quarkus.application.name=langchain-api
quarkus.http.port=9000
quarkus.langchain4j.openai.api-key=${OPENAI_API_KEY}
quarkus.langchain4j.openai.chat-model.model-name=gpt-4o-mini
quarkus.langchain4j.openai.chat-model.log-requests=true
quarkus.langchain4j.openai.chat-model.log-responses=true
quarkus.langchain4j.openai.chat-model.temperature=1.0
quarkus.langchain4j.openai.chat-model.max-completion-tokens=1000
quarkus.langchain4j.openai.chat-model.frequency-penalty=0
# If you want to use a different provider or run an LLM on your local machine,
# uncomment this line and update the url/port accordingly.
#quarkus.langchain4j.openai.base-url=http://localhost:35000/v1
quarkus.langchain4j.timeout=1m
quarkus.langchain4j.easy-rag.path=src/main/resources/rag
quarkus.langchain4j.easy-rag.max-segment-size=100
quarkus.langchain4j.easy-rag.max-overlap-size=25
quarkus.langchain4j.easy-rag.max-results=3
# Core API settings #
# Core API REST client configuration
core-api/mp-rest/url=http://localhost:8090/
core-api/mp-rest/scope=jakarta.inject.Singleton
core-api/mp-rest/connectTimeout=5000
core-api/mp-rest/readTimeout=10000
quarkus.datasource.db-kind=mssql
quarkus.datasource.username=sa
quarkus.datasource.password=changeme
quarkus.datasource.jdbc.url=jdbc:sqlserver://localhost:1433;databaseName=CarRentalDb;encrypt=false;trustServerCertificate=true
quarkus.opentelemetry.enabled=true
quarkus.datasource.jdbc.telemetry=true
quarkus.otel.logs.enabled=true
quarkus.otel.traces.enabled=true
# Disable LTGM in test mode
%test.quarkus.observability.enabled=false